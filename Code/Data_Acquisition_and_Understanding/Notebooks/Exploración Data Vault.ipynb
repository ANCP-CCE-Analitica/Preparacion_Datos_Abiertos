{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"\n",
    "  padding: 30px;\n",
    "  text-align: center;\" class='row'>\n",
    "<div style=\"float:left;width: 15%;\" class='column'><a href=\"https://www.colombiacompra.gov.co\"><img alt=\"Logo Colombia Compra Eficiente\" id=\"logocce\" src=\"https://www.colombiacompra.gov.co/sites/cce_public/files/Images/logocce.png\" style=\"height: 45px;\"></a></div>\n",
    "    <div style=\"float:left;width: 70%;\" class='column'>\n",
    "        <h1> Exploración DataVAULT\n",
    "        </h1> \n",
    "    </div>\n",
    "<div style=\"float:left;width: 15%;\" class='column'><a href=\"https://www.dnp.gov.co/\" target=\"_blank\"><img class=\"float-right\" id=\"logodnp\" src=\"https://www.dnp.gov.co/img/logoNuevo.jpg\" style=\"width: 200px;\"></a></div>\n",
    "</div>\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. IDENTIFICACIÓN DEL INSUMO\n",
    "\n",
    "|||\n",
    "|:--|:--|\n",
    "|**Fecha**|Abril 2023|\n",
    "|**Ciudad**|Bogotá D.C.|\n",
    "|**Esquema de presentación del insumo**|Cuaderno Jupyter|\n",
    "|**Título del insumo**| **Consideraciones para la consulta en datos abiertos**|\n",
    "|**Descripción y alcance**|Script para la consulta de bases y exploración de bases en el DATAVAULT.|\n",
    "|**Periodicidad del insumo**|único|\n",
    "|**Solicitante**|No aplica|\n",
    "|**Versión del insumo**|Final|"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. DESTINO Y AUTORES DEL INFORME / INSUMO\n",
    "\n",
    "|||\n",
    "|:--|:--|\n",
    "|**Destinatario**|<table align='left'><tr><td>*Nombre:*</td> <td>Equipo analítica EMAE</td></tr> <tr><td>*Cargo:*</td> <td>NA</td></tr>  <tr><td>*Área:*</td> <td>Subdirección de estudios de Mercado y Abastecimiento Estratégico – EMAE</td></tr></table>|\n",
    "|**Autores**|<table><tr><td>*Nombre:*</td> <td>Equipo de Datos -GAEC<td>*Área:*</td> <td>Subdirección de estudios de Mercado y Abastecimiento Estratégico – EMAE.</td></tr></table>|\n",
    "|**Aprobación**|<table><tr><td>*Nombre:*</td> <td>Ricardo Suarez</td></tr> <tr><td>*Cargo:*</td> <td>Subdirector Estudios de Mercado y Abastecimiento Estratégico</td></tr>  <tr><td>*Área:*</td> <td>Subdirección de estudios de Mercado y Abastecimiento Estratégico – EMAE.</td></tr></table>|"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instalaciones previas\n",
    " \n",
    "Para poder utilizar SQL en Python es necesario instalar lo siguiente, escoja el driver de acuerdo al sistema operativo de su equipo: \n",
    " \n",
    " \n",
    "**Driver Microsoft ODBC para SQL SERVER en windows**\n",
    " \n",
    "Descargar e instalar el driver de la página [Microsoft ODBC](https://docs.microsoft.com/en-us/sql/connect/odbc/windows/system-requirements-installation-and-driver-files?view=sql-server-ver15#installing-microsoft-odbc-driver-for-sql-server) versión \n",
    " 17.\n",
    " \n",
    "**Driver Microsoft ODBC para SQL SERVER en Linux o MacOs**\n",
    " \n",
    "Descargar e instalar el driver de la página [Microsoft ODBC](https://docs.microsoft.com/en-us/sql/connect/odbc/linux-mac/system-requirements?view=sql-server-ver15) versión 17 deacuerdo a la versión de su sistema operativo.\n",
    "Recuerde estar conectado a la VPN para poder accerder. \n",
    "\n",
    "**Paquete pyobdc**\n",
    "\n",
    "Quite el comentario e inicie la instalación simple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyodbc \n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()\n",
    "\n",
    "server = os.getenv(\"server\")\n",
    "username= os.getenv(\"username\")\n",
    "password= os.getenv(\"password\")\n",
    "\n",
    "cnxn = pyodbc.connect('DRIVER={ODBC Driver 17 for SQL Server};SERVER='+server+';UID='+username+';PWD='+ password)\n",
    "cursor = cnxn.cursor()\n",
    "\n",
    "ruta_DATA=\"../../../../DATA/\"\n",
    "ruta_MUESTRAS=\"../../../Sample_Data/Raw/MUESTRAS/ \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Paquetes usados para la exploración de datos\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datetime as dt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. DESCRIPCIÓN DEL INFORME / INSUMO\n",
    "\n",
    "### 3.1. Objetivo\n",
    "\n",
    "El objetivo de este cuaderno es mostrar las bases de datos disponibles en el DATAVAULT, como consultarlas y algunos usos simples de modelos de limpieza.\n",
    "\n",
    "En particular de aqui saldran las siguientes tablas para poner a disposición del público a traves del portal de datos abiertos, www.datos.gov.co:\n",
    "\n",
    "- **Tabla de procesos SECOP II**: Contiene la información de los procesos que se han llevado a cabo en el Sistema Electrónico de Contratación Pública SECOP II.\n",
    "\n",
    "- **Tabla de contratos SECOP II**: Contiene la información de los contratos que se han llevado a cabo en el Sistema Electrónico de Contratación Pública SECOP II.\n",
    "\n",
    "\n",
    "- **Tabla de procesos SECOP I**: Contiene la información de los procesos que se han llevado a cabo en el Sistema Electrónico de Contratación Pública SECOP I.\n",
    "\n",
    "-  **Tabla de plan anual de adquisiciones**: Contiene la información de las adquisiciones prioyectadas por entidad."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. ADQUISICIÓN DE LOS DATOS\n",
    "\n",
    "### 4.1. Datos de procesos SECOP II\n",
    "\n",
    "Para consultar los datos de procesos SECOP II, se debe ejecutar la siguiente consulta:\n",
    "\n",
    "```sql\n",
    "SELECT * FROM [CCE_Sandbox].[datavault].[SAT_Example_Table]\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sat_company = pd.read_sql_query(\"SELECT * FROM [CCE_Sandbox].[datavault].[Sat_Company]\", cnxn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sat_company.to_parquet(ruta_DATA+\"sat_company.parquet\", engine='pyarrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sat_buyer_dossier = pd.read_sql_query(\"SELECT * FROM [CCE_Sandbox].[datavault].[Sat_BuyerDossier]\", cnxn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sat_buyer_dossier.to_parquet(ruta_DATA+\"sat_buyer_dossier.parquet\",engine='pyarrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sat_categorization = pd.read_sql_query(\"SELECT * FROM [CCE_Sandbox].[datavault].[Sat_Categorization]\", cnxn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sat_categorization.to_parquet(ruta_DATA+\"sat_categorization.parquet\",engine='pyarrow')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inicia la consulta en 0\n",
      "Inicia la consulta en 500000\n",
      "Inicia la consulta en 1000000\n",
      "Inicia la consulta en 1500000\n",
      "Inicia la consulta en 2000000\n",
      "Inicia la consulta en 2500000\n",
      "Inicia la consulta en 3000000\n"
     ]
    }
   ],
   "source": [
    "## sat_procedure_request lo bajaremos en bloques de 1000000\n",
    "\n",
    "n=pd.read_sql_query(\"SELECT COUNT(*) FROM [CCE_Sandbox].[datavault].[Sat_ProcedureRequest]\", cnxn).values[0][0]\n",
    "list_sat_procedure_request=[]\n",
    "for i in range(0,n,500000):\n",
    "    print(\"Inicia la consulta en\", i)\n",
    "    sat_procedure_request_temp = pd.read_sql_query(\"SELECT * FROM [CCE_Sandbox].[datavault].[Sat_ProcedureRequest] ORDER BY [HubProcedureRequestHashKey] OFFSET \"+str(i)+\" ROWS FETCH NEXT 1000000 ROWS ONLY\", cnxn)\n",
    "    list_sat_procedure_request.append(sat_procedure_request_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sat_procedure_request=pd.concat(list_sat_procedure_request)\n",
    "sat_procedure_request.to_parquet(ruta_DATA+\"sat_procedure_request.parquet\",engine='pyarrow')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### cerramos la conexión\n",
    "cnxn.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga de datos usando Python desde la ruta DATA\n",
    "\n",
    "Cargamos la base desde la ruta DATA\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "ruta_DATA=\"../../../../DATA/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ArrowInvalid",
     "evalue": "Casting from timestamp[us] to timestamp[ns] would result in out of bounds timestamp: 21116350800000000",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mArrowInvalid\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/dropbox/Dropbox/CCE-projects/Proyecto Datos Abiertos/Preparacion_Datos_Abiertos/Code/Data_Acquisition_and_Understanding/Notebooks/Exploración Data Vault.ipynb Celda 20\u001b[0m in \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/dropbox/Dropbox/CCE-projects/Proyecto%20Datos%20Abiertos/Preparacion_Datos_Abiertos/Code/Data_Acquisition_and_Understanding/Notebooks/Exploraci%C3%B3n%20Data%20Vault.ipynb#X25sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m sat_company \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_parquet(ruta_DATA\u001b[39m+\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39msat_company.parquet\u001b[39;49m\u001b[39m\"\u001b[39;49m,engine\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mpyarrow\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/dropbox/Dropbox/CCE-projects/Proyecto%20Datos%20Abiertos/Preparacion_Datos_Abiertos/Code/Data_Acquisition_and_Understanding/Notebooks/Exploraci%C3%B3n%20Data%20Vault.ipynb#X25sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m sat_buyer_dossier \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_parquet(ruta_DATA\u001b[39m+\u001b[39m\u001b[39m\"\u001b[39m\u001b[39msat_buyer_dossier.parquet\u001b[39m\u001b[39m\"\u001b[39m,engine\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mpyarrow\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/dropbox/Dropbox/CCE-projects/Proyecto%20Datos%20Abiertos/Preparacion_Datos_Abiertos/Code/Data_Acquisition_and_Understanding/Notebooks/Exploraci%C3%B3n%20Data%20Vault.ipynb#X25sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m sat_categorization \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_parquet(ruta_DATA\u001b[39m+\u001b[39m\u001b[39m\"\u001b[39m\u001b[39msat_categorization.parquet\u001b[39m\u001b[39m\"\u001b[39m,engine\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mpyarrow\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/pandas/io/parquet.py:509\u001b[0m, in \u001b[0;36mread_parquet\u001b[0;34m(path, engine, columns, storage_options, use_nullable_dtypes, dtype_backend, **kwargs)\u001b[0m\n\u001b[1;32m    506\u001b[0m     use_nullable_dtypes \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    507\u001b[0m check_dtype_backend(dtype_backend)\n\u001b[0;32m--> 509\u001b[0m \u001b[39mreturn\u001b[39;00m impl\u001b[39m.\u001b[39;49mread(\n\u001b[1;32m    510\u001b[0m     path,\n\u001b[1;32m    511\u001b[0m     columns\u001b[39m=\u001b[39;49mcolumns,\n\u001b[1;32m    512\u001b[0m     storage_options\u001b[39m=\u001b[39;49mstorage_options,\n\u001b[1;32m    513\u001b[0m     use_nullable_dtypes\u001b[39m=\u001b[39;49muse_nullable_dtypes,\n\u001b[1;32m    514\u001b[0m     dtype_backend\u001b[39m=\u001b[39;49mdtype_backend,\n\u001b[1;32m    515\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m    516\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/pandas/io/parquet.py:230\u001b[0m, in \u001b[0;36mPyArrowImpl.read\u001b[0;34m(self, path, columns, use_nullable_dtypes, dtype_backend, storage_options, **kwargs)\u001b[0m\n\u001b[1;32m    226\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    227\u001b[0m     pa_table \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapi\u001b[39m.\u001b[39mparquet\u001b[39m.\u001b[39mread_table(\n\u001b[1;32m    228\u001b[0m         path_or_handle, columns\u001b[39m=\u001b[39mcolumns, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs\n\u001b[1;32m    229\u001b[0m     )\n\u001b[0;32m--> 230\u001b[0m     result \u001b[39m=\u001b[39m pa_table\u001b[39m.\u001b[39;49mto_pandas(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mto_pandas_kwargs)\n\u001b[1;32m    232\u001b[0m     \u001b[39mif\u001b[39;00m manager \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39marray\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    233\u001b[0m         result \u001b[39m=\u001b[39m result\u001b[39m.\u001b[39m_as_manager(\u001b[39m\"\u001b[39m\u001b[39marray\u001b[39m\u001b[39m\"\u001b[39m, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/pyarrow/array.pxi:830\u001b[0m, in \u001b[0;36mpyarrow.lib._PandasConvertible.to_pandas\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/pyarrow/table.pxi:3990\u001b[0m, in \u001b[0;36mpyarrow.lib.Table._to_pandas\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/pyarrow/pandas_compat.py:820\u001b[0m, in \u001b[0;36mtable_to_blockmanager\u001b[0;34m(options, table, categories, ignore_metadata, types_mapper)\u001b[0m\n\u001b[1;32m    818\u001b[0m _check_data_column_metadata_consistency(all_columns)\n\u001b[1;32m    819\u001b[0m columns \u001b[39m=\u001b[39m _deserialize_column_index(table, all_columns, column_indexes)\n\u001b[0;32m--> 820\u001b[0m blocks \u001b[39m=\u001b[39m _table_to_blocks(options, table, categories, ext_columns_dtypes)\n\u001b[1;32m    822\u001b[0m axes \u001b[39m=\u001b[39m [columns, index]\n\u001b[1;32m    823\u001b[0m \u001b[39mreturn\u001b[39;00m BlockManager(blocks, axes)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/pyarrow/pandas_compat.py:1169\u001b[0m, in \u001b[0;36m_table_to_blocks\u001b[0;34m(options, block_table, categories, extension_columns)\u001b[0m\n\u001b[1;32m   1164\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_table_to_blocks\u001b[39m(options, block_table, categories, extension_columns):\n\u001b[1;32m   1165\u001b[0m     \u001b[39m# Part of table_to_blockmanager\u001b[39;00m\n\u001b[1;32m   1166\u001b[0m \n\u001b[1;32m   1167\u001b[0m     \u001b[39m# Convert an arrow table to Block from the internal pandas API\u001b[39;00m\n\u001b[1;32m   1168\u001b[0m     columns \u001b[39m=\u001b[39m block_table\u001b[39m.\u001b[39mcolumn_names\n\u001b[0;32m-> 1169\u001b[0m     result \u001b[39m=\u001b[39m pa\u001b[39m.\u001b[39;49mlib\u001b[39m.\u001b[39;49mtable_to_blocks(options, block_table, categories,\n\u001b[1;32m   1170\u001b[0m                                     \u001b[39mlist\u001b[39;49m(extension_columns\u001b[39m.\u001b[39;49mkeys()))\n\u001b[1;32m   1171\u001b[0m     \u001b[39mreturn\u001b[39;00m [_reconstruct_block(item, columns, extension_columns)\n\u001b[1;32m   1172\u001b[0m             \u001b[39mfor\u001b[39;00m item \u001b[39min\u001b[39;00m result]\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/pyarrow/table.pxi:2646\u001b[0m, in \u001b[0;36mpyarrow.lib.table_to_blocks\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/pyarrow/error.pxi:100\u001b[0m, in \u001b[0;36mpyarrow.lib.check_status\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mArrowInvalid\u001b[0m: Casting from timestamp[us] to timestamp[ns] would result in out of bounds timestamp: 21116350800000000"
     ]
    }
   ],
   "source": [
    "sat_company = pd.read_parquet(ruta_DATA+\"sat_company.parquet\",engine=\"pyarrow\")\n",
    "sat_buyer_dossier = pd.read_parquet(ruta_DATA+\"sat_buyer_dossier.parquet\",engine=\"pyarrow\")\n",
    "sat_categorization = pd.read_parquet(ruta_DATA+\"sat_categorization.parquet\",engine=\"pyarrow\")\n",
    "sat_procedure_request = pd.read_parquet(ruta_DATA+\"sat_procedure_request.parquet\",engine=\"pyarrow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "### Para el repositorio generamos muestras de los dataframes y los guardamos en archivos csv\n",
    "\n",
    "sat_company.sample(100).to_csv(ruta_DATA+\"sat_company.csv\")\n",
    "sat_buyer_dossier.sample(100).to_csv(ruta_DATA+\"sat_buyer_dossier.csv\")\n",
    "sat_categorization.sample(100).to_csv(ruta_DATA+\"sat_categorization.csv\")\n",
    "sat_procedure_request.sample(100).to_csv(ruta_DATA+\"sat_procedure_request.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# unir las tablas utilizando las claves\n",
    "procesos = pd.merge(sat_buyer_dossier, sat_procedure_request, on='BuyerDossierUniqueIdentifier', how='left')\n",
    "proc_comp_buyer = pd.merge(procesos, sat_categorization, on='HubProcedureRequestHashKey', how='left')\n",
    "proc_comp_buyer_cat = pd.merge(proc_comp_buyer, sat_categorization, on='HubProcedureRequestHashKey', how='left')\n",
    "\n",
    "\n",
    "result = proc_comp_buyer_cat[columns]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
